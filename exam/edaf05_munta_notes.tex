\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{multicol}
\usepackage{titlesec}
\usepackage{parskip}
\setlength{\parskip}{0.1em}  % Reduce the space between paragraphs
\geometry{a4paper, margin=0.4in}

% Adjust spacing for sections and subsections
\titlespacing{\section}{0pt}{12pt}{4pt}
\titlespacing{\subsection}{0pt}{10pt}{3pt}
\titlespacing{\subsubsection}{0pt}{8pt}{2pt}
\titlespacing{\paragraph}{0pt}{7pt}{2pt}

% Make itemize environments more compact
\usepackage{enumitem}
\setlist[itemize]{topsep=0pt, itemsep=0pt, parsep=0pt, leftmargin=*}

\title{EDAF05 Algorithms, Data Structures and Time \& Space Complexity}
\author{Adam Tovatt}
\date{2025-06-14}

% Redefine maketitle to be smaller and left-aligned
\makeatletter
\renewcommand{\maketitle}{%
  \begin{flushleft}
    {\large\bfseries\@title}\hspace{1em}{\small\@author}\hspace{1em}{\small\@date}
  \end{flushleft}
  \vspace{0.5em}
}
\makeatother

\begin{document}

\maketitle

\begin{multicols}{2}
\section{Asymptotic Notation}
\subsection{What do O(n), $\Omega$(n), and $\Theta$(n) mean?}

1. \textbf{O(n) - Big O Notation}
\begin{itemize}
    \item Tells us "it will never be slower than this" - upper bound on growth rate. Example: 2n + 3 is O(n) because it grows linearly
\end{itemize}

2. \textbf{$\Omega$(n) - Big Omega Notation}
\begin{itemize}
    \item Tells us "it will never be faster than this" - lower bound on growth rate. Example: 2n + 3 is $\Omega$(n) because it can't grow slower than linear
\end{itemize}

3. \textbf{$\Theta$(n) - Big Theta Notation}
\begin{itemize}
    \item Tells us "it will always be exactly this" - tight bound. Example: 2n + 3 is $\Theta$(n) because it's both O(n) and $\Omega$(n)
\end{itemize}

\subsection{Real Examples}
\begin{itemize}
    \item \textbf{Bubble Sort}: Best $\Theta$(n), Worst/Avg $\Theta$(n$^2$)
    \item \textbf{Binary Search}: Best O(1), Worst $\Theta$(log n)
    \item \textbf{Linear Search}: Best O(1), Worst $\Theta$(n)
\end{itemize}

\subsection{Important Notes}
\begin{itemize}
    \item O notation can describe any bound (worst, best, or average case) - we must specify which case we're analyzing. Often it could be the worst case for an algorithm if nothing else is specified.
    \item We can use $\Theta$ to describe an algorithm's complexity if all its executions fall within $\Theta(f(n))$, even if theoretical best/worst cases differ
    \item The key is whether the actual running time is tightly bounded, not whether best/worst cases are identical
\end{itemize}

\subsection{Common Time Complexities}
\begin{itemize}
    \item O(1): Constant (array access), O(log n): Logarithmic (binary search)
    \item O(n): Linear (linear search), O(n log n): Linearithmic (merge sort)
    \item O(n$^2$): Quadratic (bubble sort), O($2^n$): Exponential (recursive Fibonacci)
\end{itemize}

\subsection{Space Complexity}
\begin{itemize}
    \item Similar to time complexity but for memory usage. Example: O(n) space = memory proportional to input size
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain what O(n), $\Omega$(n), and $\Theta$(n) mean.
    \item \textbf{A:} O(n) is an upper bound (never grows faster), $\Omega$(n) is a lower bound (never grows slower), and $\Theta$(n) means both bounds are tight (grows exactly at that rate).

    \item \textbf{Q:} Explain the difference between O(n) and $\Theta$(n) using a concrete example.
    \item \textbf{A:} Consider linear search: it's O(n) because it never takes more than n steps, but it's not $\Theta$(n) because in the best case (element found first) it takes O(1) time. For an example of $\Theta$(n), consider a loop that always processes each element exactly once.

    \item \textbf{Q:} Why might an algorithm have different time complexities for its best and worst cases? Give an example.
    \item \textbf{A:} Algorithms often have early exit conditions or different paths based on input. For example, linear search is O(1) in best case (element found first) but $\Theta$(n) in worst case (element not found or found last) because it might find the element immediately or need to check every position.

    \item \textbf{Q:} How can you determine if an algorithm's time complexity is $\Theta$(n) rather than just O(n)?
    \item \textbf{A:} To prove $\Theta$(n), you need to show both O(n) and $\Omega$(n). This means proving the algorithm never takes more than cn steps (O(n)) AND never takes fewer than dn steps ($\Omega$(n)) for some constants c and d. For example, a loop that always processes each element exactly once is $\Theta$(n) because it takes exactly n steps.

    \item \textbf{Q:} Explain why we often focus on worst-case analysis when using O notation.
    \item \textbf{A:} Worst-case analysis gives us a guarantee that the algorithm will never perform worse than the bound, which is crucial for reliability and performance guarantees. It helps us prepare for the most challenging scenarios and ensures our solution will work efficiently even in the most demanding cases.
\end{itemize}

\section{Stable Matching}
\textbf{Stable Matching} is a problem in which we (for example) want to match n men and n women where each person has ranked all members of opposite sex. The goal is to find a matching where no two people would prefer each other over their current partners.
\begin{itemize}
    \item A matching is stable if no pair (A,B) exists where:
        \begin{itemize}
            \item A prefers B over their current match
            \item B prefers A over their current match
        \end{itemize}
\end{itemize}

\subsection{Gale-Shapley Algorithm}
\begin{itemize}
    \item Each man proposes to his most preferred woman who hasn't rejected him
    \item Each woman accepts if:
        \begin{itemize}
            \item She is unmatched, or
            \item She prefers the new proposal over her current match
        \end{itemize}
    \item Process continues until everyone is matched
    \item Always produces a stable matching
    \item Proposer-optimal, meaning the proposer gets the best possible stable matching for them.
\end{itemize}

\subsection{Time Complexity}
\begin{itemize}
    \item O(n²) where n is number of men/women
    \item Each man proposes at most n times
    \item n men making proposals
    \item Total: n * n = O(n²)
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain why the Gale-Shapley algorithm finds a stable matching.
    \item \textbf{A:} Gale-Shapley always finds a stable matching because it continues until everyone is matched and no pair would prefer each other over their current matches.

    \item \textbf{Q:} Can there be multiple stable matchings for the same set of preferences? Give an example.
    \item \textbf{A:} Yes, there can be multiple stable matchings. For example, with 2 men (A,B) and 2 women (X,Y), if A prefers X>Y, B prefers Y>X, X prefers B>A, and Y prefers A>B, then both (A-X, B-Y) and (A-Y, B-X) are stable matchings.

    \item \textbf{Q:} What happens if we reverse the roles in Gale-Shapley (women propose to men)?
    \item \textbf{A:} The algorithm still works but it will be women-optimal instead of men-optimal. In this algorithm the one who proposes is the one who gets the best possible stable matching.

    \item \textbf{Q:} Why can't a man be rejected by all women in the Gale-Shapley algorithm?
    \item \textbf{A:} Because there are equal numbers of men and women, and each woman can only be matched to one man. If a man was rejected by all women, it would mean all women are matched to other men, which is impossible since there are n men and n women.
\end{itemize}

\section{Data Structures}
\subsection{Priority Queue}
\begin{itemize}
    \item A data structure that always gives the element with highest (or lowest) priority
    \item Internal Implementation:
    \begin{itemize}
        \item Stored as a binary heap in a contiguous array
        \item For any element at index $i$:
        \begin{itemize}
            \item Left child is at index $2i + 1$
            \item Right child is at index $2i + 2$
            \item Parent is at index $\lfloor(i-1)/2\rfloor$
        \end{itemize}
        \item In a min-heap, each parent node must be less than or equal to its children (smallest element at root). A max-heap is the opposite - each parent is greater than or equal to its children (largest element at root)
    \end{itemize}
    \item Main Operations:
    \begin{itemize}
        \item \textbf{Insert(x)}:
        \begin{itemize}
            \item Add element at the end of the array
            \item "Bubble up" by swapping with parent until heap property is satisfied
            \item Time complexity: O(log n)
        \end{itemize}
        \item \textbf{ExtractMin()} (or \textbf{ExtractMax()}):
        \begin{itemize}
            \item Remove root element
            \item Move last element to root
            \item "Bubble down" by swapping with the smaller of the two children until heap property is satisfied
            \item Time complexity: O(log n)
        \end{itemize}
        \item \textbf{Peek()}:
        \begin{itemize}
            \item Simply return the root element (index 0)
            \item Time complexity: O(1)
        \end{itemize}
    \end{itemize}
    \item Applications:
    \begin{itemize}
        \item Dijkstra's algorithm (for shortest paths)
        \item Prim's algorithm (for MSTs)
        \item Task scheduling
        \item Event-driven simulation
    \end{itemize}
\end{itemize}

\subsection{Union-Find}
\begin{itemize}
    \item A simple data structure for tracking connected components
    \item Implementation:
    \begin{itemize}
        \item Parent array: index = vertex, value = parent vertex
        \item Rank array: index = vertex, value = height of tree rooted at vertex
        \item If a vertex is its own parent, it's a root
        \item Example: 
        \begin{itemize}
            \item Parent array: [0, 0, 1, 1]
            \item Rank array: [1, 2, 0, 0]
            \item Means:
            \begin{itemize}
                \item Vertices 0 and 1 are roots (they point to themselves)
                \item Vertex 2's parent is 1
                \item Vertex 3's parent is 1
                \item Tree at 0 has height 1
                \item Tree at 1 has height 2
                \item So vertices 0, 1, 2, and 3 form two trees: {0} and {1,2,3}
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item Operations:
    \begin{itemize}
        \item Find: Follow parent pointers until we reach a root
        \item Union: Make root of smaller tree point to root of larger tree
    \end{itemize}
    \item Optimizations:
    \begin{itemize}
        \item Path Compression: During Find, make all nodes point directly to root
        \item Union by Rank: Use rank array to always attach smaller tree to larger one
    \end{itemize}
    \item Time Complexity: O($\alpha$(n)) where $\alpha$ is the inverse Ackermann function (a function that grows so slowly it's practically constant)
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} What can make the naïve version of union-find slow?
    \item \textbf{A:} The naïve version can degenerate into linear chains, making find operations O(n) and union operations potentially slow.

    \item \textbf{Q:} Explain how union-find can be made faster than as in the naïve version.
    \item \textbf{A:} Use path compression (make all nodes point directly to root during find) and union by rank (attach smaller tree to larger one) to achieve nearly constant time operations.
\end{itemize}

\subsection{Hash Tables}
A hash table stores key-value pairs and provides fast lookups. It uses a hash function to convert keys into array indices.

\begin{itemize}
    \item \textbf{How it works:}
    \begin{itemize}
        \item Hash Function: Converts key to a number
        \item Modulo Operation: Converts hash to array index
        \item Collision Handling: When two keys map to same index
    \end{itemize}

    \item \textbf{Collision Handling Methods:}
    \begin{itemize}
        \item \textbf{Separate Chaining}
        \begin{itemize}
            \item Each array slot holds a list
            \item Colliding items go in the same list
            \item Simple but can get slow with long lists
        \end{itemize}
        \item \textbf{Open Addressing}
        \begin{itemize}
            \item Try to find another empty slot ("probing")
            \item Types of probing:
            \begin{itemize}
                \item \textbf{Linear}: try next slot, then next, etc.
                \item \textbf{Quadratic}: try slots with increasing gaps like +1, +4, +9, etc.
                \item \textbf{Double hashing}: use two different hash functions - first one gives initial position, second one gives step size for probing
            \end{itemize}
        \end{itemize}
    \end{itemize}

    \item \textbf{Deletion in Open Addressing:}
    \begin{itemize}
        \item Can't just clear slot (breaks probe chain)
        \item Two approaches:
        \begin{itemize}
            \item Use tombstone (special marker)
            \item Move items back (more complex)
        \end{itemize}
    \end{itemize}

    \item \textbf{Load Factor ($\alpha$):}
    \begin{itemize}
        \item $\alpha$ = number of items / total slots
        \item Affects performance and insertion success
        \item Different methods have different limits:
        \begin{itemize}
            \item Separate chaining: works with $\alpha$ > 1
            \item Linear probing: works up to $\alpha$ $\approx$ 0.7-0.9
            \item Quadratic probing: keep $\alpha$ $\leq$ 0.5
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} With open addressing, how can pairs be deleted?
    \item \textbf{A:} Use a special marker (tombstone) to mark deleted slots, or move elements back to maintain the probe chain.

    \item \textbf{Q:} What does quadratic probing mean?
    \item \textbf{A:} When a collision occurs, try slots at increasing squared distances (h+1, h+4, h+9, etc.) from the original hash position.

    \item \textbf{Q:} What does double hashing mean? Why can $\alpha$ be larger with double hashing than with quadratic probing?
    \item \textbf{A:} Use two different hash functions to determine the probe sequence; it can handle higher load factors because it provides better distribution of probes.

    \item \textbf{Q:} Why can't we just delete a slot in open addressing by setting it to empty? What problems would this cause?
    \item \textbf{A:} Setting a slot to empty would break the probe chain. If we later search for a key that was inserted after the deleted item, we would stop at the empty slot and never find the key, even though it exists in the table.

    \item \textbf{Q:} Compare the advantages and disadvantages of separate chaining versus open addressing.
    \item \textbf{A:} Separate chaining is simpler to implement and can handle any load factor, but uses more memory and can be slower due to list traversal. Open addressing is more memory efficient and can be faster due to better cache locality, but is more complex to implement and has stricter load factor limits.

    \item \textbf{Q:} What happens to the performance of a hash table as the load factor increases? Why?
    \item \textbf{A:} Performance degrades as load factor increases because there are more collisions, leading to longer probe sequences in open addressing or longer chains in separate chaining. This means more comparisons are needed to find or insert items.

    \item \textbf{Q:} Why might quadratic probing be better than linear probing in practice?
    \item \textbf{A:} Quadratic probing helps avoid primary clustering (where items cluster around the same initial positions) by spreading out the probe sequence. This leads to more even distribution of items and better performance, especially at higher load factors.
\end{itemize}

\subsection{Graph Representations}
\begin{itemize}
    \item \textbf{Adjacency Matrix:}
    \begin{itemize}
        \item 2D array where A[i][j] = 1 if edge exists between vertex i and vertex j
        \item Indices i and j correspond to vertex numbers (e.g., vertex 0, 1, 2, etc.)
        \item For a graph with n vertices, matrix is n $\times$ n
        \item Example: If A[2][3] = 1, there's an edge from vertex 2 to vertex 3
        \item Space: $\Theta$(Vertices$^2$)
        \item Good for dense graphs (many edges)
        \item Fast edge lookup: O(1)
    \end{itemize}

    \item \textbf{Adjacency List:}
    \begin{itemize}
        \item Array of lists, where each list contains neighbors
        \item Space: $\Theta$(Vertices + Edges)
        \item Good for sparse graphs (few edges)
        \item Slower edge lookup: O(number of edges connected to vertex)
    \end{itemize}
\end{itemize}

\subsection{Graph Traversal}
\begin{itemize}
    \item \textbf{Depth-First Search (DFS):}
    \begin{itemize}
        \item Explore as far as possible along each branch before backtracking
        \item Uses stack (implicitly in recursion)
        \item Time: O(Vertices + Edges)
        \item Applications: cycle detection, topological sort, maze solving
    \end{itemize}

    \item \textbf{Breadth-First Search (BFS):}
    \begin{itemize}
        \item Explore all neighbors at current depth before moving deeper
        \item Uses queue
        \item Time: O(Vertices + Edges)
        \item Applications: shortest path (unweighted), level-order traversal
    \end{itemize}
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} When would you choose an adjacency matrix over an adjacency list?
    \item \textbf{A:} Use adjacency matrix when the graph is dense (many edges) and you need fast edge lookups. The O(1) edge lookup time can be worth the extra space for dense graphs.

    \item \textbf{Q:} What's the main difference between DFS and BFS?
    \item \textbf{A:} DFS explores as far as possible along each branch before backtracking, while BFS explores all neighbors at the current depth before moving deeper. This makes BFS better for finding shortest paths in unweighted graphs.

    \item \textbf{Q:} Why is the time complexity of both DFS and BFS O(Vertices + Edges)?
    \item \textbf{A:} Both visit each vertex once and each edge once. The total work is the sum of visiting all vertices and exploring all edges.
    
    \item \textbf{Q:} In a maze-solving problem, why might DFS be better than BFS?
    \item \textbf{A:} DFS is better for maze-solving because it explores one path completely before backtracking, which is more memory-efficient than BFS's level-by-level approach. DFS also naturally follows the physical structure of a maze.

    \item \textbf{Q:} How would you detect a cycle in an undirected graph using DFS or BFS?
    \item \textbf{A:} Both algorithms detect cycles the same way: if you encounter a vertex that's already been visited and it's not the parent of the current vertex, then you've found a cycle. The only difference is that BFS will find the cycle through vertices at similar levels, while DFS might find it through a deeper path.

    \item \textbf{Q:} Why does BFS guarantee the shortest path in an unweighted graph?
    \item \textbf{A:} BFS explores vertices in order of their distance from the start vertex. When it first visits a vertex, it must be through the shortest path because any longer path would have to go through vertices that haven't been visited yet.

    \item \textbf{Q:} What does it mean that a directed graph is strongly connected, and how can you use BFS to determine if a graph is strongly connected?
    \item \textbf{A:} A graph is strongly connected if every vertex can reach every other vertex; use BFS from any vertex, then reverse all edges and do BFS again from the same vertex - if all vertices are reachable in both cases, the graph is strongly connected.
\end{itemize}

\section{Greedy Algorithms}
Greedy algorithms make locally optimal choices at each step, hoping to find a global optimum. They are simple to implement and often efficient, but don't always find the optimal solution.

\subsection{Key Characteristics}
\begin{itemize}
    \item Makes decisions one at a time
    \item Never reconsider previous choices
    \item Always takes the best immediate option
\end{itemize}

\subsection{Common Applications}
\begin{itemize}
    \item Scheduling problems
    \item Minimum spanning trees (Prim's and Kruskal's)
    \item Huffman coding
    \item Activity selection
\end{itemize}

\subsection{Proving Correctness}
There are two main approaches to prove a greedy algorithm is correct:
\begin{itemize}
    \item Exchange argument:
    \begin{itemize}
        \item Assume there's a better solution
        \item Show we can exchange elements to match our greedy solution
        \item Prove this doesn't make the solution worse
        \item Example: In activity selection, if we can swap activities, we can always choose the one that ends first
    \end{itemize}
    \item Greedy stays ahead:
    \begin{itemize}
        \item Show greedy solution is at least as good at each step
        \item Compare with any other solution
        \item Prove it maintains this advantage
        \item Example: In Huffman coding, show greedy choice leads to optimal prefix code
    \end{itemize}
\end{itemize}

\subsection{Example: Activity Selection}
\begin{itemize}
    \item Problem: Select maximum number of activities that don't overlap
    \item Greedy choice: Always pick the activity with earliest finish time
    \item Why it works: Leaves maximum time for remaining activities
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Suppose you have invented a greedy algorithm that finds an optimal solution to a problem. Explain two approaches to prove its output really is optimal.
    \item \textbf{A:} Use an exchange argument to show any optimal solution can be transformed into the greedy solution, or use greedy stays ahead to show the greedy solution is always at least as good as any other solution at each step.
\end{itemize}

\section{Shortest Paths and MSTs}
\subsection{Minimum Spanning Trees (MST)}
\begin{itemize}
    \item A tree that connects all vertices with minimum total edge weight
    \item Properties:
    \begin{itemize}
        \item No cycles (by definition of a tree)
        \item Connects all vertices
        \item Has exactly Vertices-1 edges
    \end{itemize}
    \item Applications:
    \begin{itemize}
        \item Network design (minimizing cost of wiring/cables)
        \item Road planning
        \item Clustering
    \end{itemize}
\end{itemize}

\subsection{Creating an MST: Dijkstra's Algorithm}
\begin{itemize}
    \item Finds shortest paths from a source vertex to all other vertices
    \item Key idea: Always process the vertex with smallest known distance
    \item Process:
    \begin{itemize}
        \item Use priority queue to track vertices by their current distance (to source (when we say distance we always mean distance to source))
        \item Initialize distances array: 0 for source, $\infty$ for all others
        \item Initialize visited array: all vertices marked as unvisited
        \item For each vertex:
        \begin{itemize}
            \item For each unvisited neighbor:
            \begin{itemize}
                \item Calculate new distance = current vertex's distance + edge weight
                \item If new distance is shorter than current best in the distance array, update distance array
                \item Add neighbor to priority queue if not present, or update its distance in queue if already present (using a hash map to find its position)
            \end{itemize}
            \item Mark current vertex as visited in visited array
        \end{itemize}
    \end{itemize}
    \item Properties:
    \begin{itemize}
        \item Works only with non-negative edge weights
        \item Gives shortest path when all weights are positive
        \item Uses a priority queue for efficiency
    \end{itemize}
    \item Time complexity: O((Vertices + Edges)log Vertices)
    \item Space complexity: O(Vertices) for distances and priority queue
\end{itemize}

\subsection{Jarnik's Algorithm (Prim)}
\begin{itemize}
    \item Builds MST by growing a single tree from a starting vertex
    \item Key idea: Always add the cheapest edge that connects to a new vertex
    \item Process:
    \begin{itemize}
        \item Start with any vertex
        \item Keep track of cheapest edge to each unvisited vertex
        \item At each step:
        \begin{itemize}
            \item Add vertex with cheapest connecting edge
            \item Update costs to unvisited neighbors
            \item Mark vertex as visited
        \end{itemize}
    \end{itemize}
    \item Properties:
    \begin{itemize}
        \item Always maintains a single connected tree
        \item Guarantees minimum total weight
        \item Similar to Dijkstra's but focuses on edge weights, not path lengths
    \end{itemize}
    \item Time complexity: O((Vertices + Edges)log Vertices)
    \item Space complexity: O(Vertices) for costs and priority queue
\end{itemize}

\subsection{Kruskal's Algorithm}
\begin{itemize}
    \item Builds MST by adding edges in order of increasing weight
    \item Key idea: Always add the smallest edge that connects two different trees
    \item (Sorting can be reversed to get a max-spanning tree instead of min-spanning tree)
    \item Process:
    \begin{itemize}
        \item Sort all edges by weight so that we can later know that we are adding edges in order of increasing weight, smallest first
        \item Start with empty graph
        \item For each edge in sorted order:
        \begin{itemize}
            \item Add edge if it connects two different trees (using Union-Find to check)
            \item Skip edge if it would connect vertices in the same tree
        \end{itemize}
    \end{itemize}
    \item Implementation details:
    \begin{itemize}
        \item Use Union-Find data structure to track connected components
        \item Path compression and union by rank for efficiency
    \end{itemize}

    \item Time complexity is O(M log M) where M is number of edges and is dominated by sorting of edges.

    \item Properties:
    \begin{itemize}
        \item Can handle disconnected components initially
        \item Works with any graph structure
        \item Produces same total weight as Prim's (though different edges)
    \end{itemize}
    \item Real-world considerations:
    \begin{itemize}
        \item No redundancy in final tree - if an edge fails, network becomes disconnected and needs to be recomputed
    \end{itemize}
    \item Applications:
    \begin{itemize}
        \item Any scenario where you need to:
        \begin{itemize}
            \item Connect all points
            \item Minimize total cost
            \item Have exactly one unique path between any two points
        \end{itemize}
        \item For example: Network design (minimizing cost of wiring/cables), clustering, road planning
    \end{itemize}
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain how Tarjan's algorithm can find the strongly connected components in a directed graph.
    \item \textbf{A:} Tarjan's algorithm uses a single DFS pass, tracking discovery time and low link values to identify SCCs when a vertex's low link equals its discovery time.

    \item \textbf{Q:} What is a bipartite graph, and how can you determine if a graph is bipartite?
    \item \textbf{A:} A bipartite graph can be divided into two sets with no edges within the same set; use BFS or DFS with two colors, coloring each vertex opposite to its neighbors.

    \item \textbf{Q:} Explain how Dijkstra's algorithm works and why it is correct.
    \item \textbf{A:} Dijkstra's algorithm always processes the vertex with smallest known distance, updating distances to neighbors; it's correct because once a vertex is processed, its distance cannot be improved.

    \item \textbf{Q:} Explain how the Bellman-Ford algorithm works and why it is correct.
    \item \textbf{A:} Bellman-Ford relaxes all edges V-1 times; it's correct because the longest possible shortest path has V-1 edges, and after V-1 iterations, all distances must be correct.

    \item \textbf{Q:} What is a safe edge for miminum spanning trees?
    \item \textbf{A:} A safe edge is one that can be added to the current partial MST without creating a cycle and is part of some MST of the graph.
    
    \item \textbf{Q:} Why does Dijkstra's algorithm only work with non-negative edge weights?
    \item \textbf{A:} With negative weights, the "greedy" choice of always taking the shortest path might not be optimal. A longer path with negative edges could actually be shorter than a direct path with positive edges.

    \item \textbf{Q:} What's the main difference between Prim's and Kruskal's algorithms?
    \item \textbf{A:} Prim's grows a single tree by always adding the cheapest edge that connects to a new vertex, while Kruskal's builds multiple trees and merges them by adding the cheapest edge that doesn't create a cycle (aka doesn't connect two vertices in the same tree).

    \item \textbf{Q:} Why do we need the Union-Find data structure in Kruskal's algorithm?
    \item \textbf{A:} Union-Find efficiently tracks which vertices are connected, allowing us to quickly check if adding an edge would create a cycle. Without it, we'd need to do a full graph traversal to check for cycles, which would be much slower.

    \item \textbf{Q:} How does path compression in Union-Find improve performance?
    \item \textbf{A:} Path compression makes all nodes point directly to their root during a Find operation, flattening the tree structure. This makes future operations faster because we don't have to traverse long chains of parent pointers.

    \item \textbf{Q:} Why does Kruskal's algorithm produce an MST?
    \item \textbf{A:} Kruskal's algorithm always picks the smallest available edge that doesn't create a cycle. This ensures minimal total weight and guarantees all nodes are connected without cycles — which defines a Minimum Spanning Tree.

    \item \textbf{Q:} What is the time complexity of Kruskal's algorithm, and why?
    \item \textbf{A:} The time complexity is O(M log M). This is because fastest possible sorting algorithm works by repeatedly splitting the list in the middle, which takes log M steps, and at each step it processes all M edges — so the total work is M · log M. Sorting takes the majority of the time and the union-find operations are nearly constant time due to path compression and union by rank. This leaves us with O(M log M).

    \item \textbf{Q:} What happens if an included edge collapses in real applications?
    \item \textbf{A:} The network becomes disconnected since it's already the minimal amount of edges possible.

    \item \textbf{Q:} What happens if the graph is disconnected? Can Kruskal's still find an MST?
    \item \textbf{A:} The algorithm will naturally handle disconnected components by not adding edges between them creating a collection of MSTs

    \item \textbf{Q:} Can Dijkstra's algorithm handle negative edge weights?
    \item \textbf{A:} No, Dijkstra's algorithm cannot handle negative edge weights. This is because the algorithm assumes that the shortest path to a vertex is found when we first visit it. With negative weights, a longer path with negative edges could actually be shorter than a direct path with positive edges, breaking this assumption.

    \item \textbf{Q:} Can both Kruskal's and Prim's algorithms handle negative edge weights?
    \item \textbf{A:} Yes. Because they only care about the relative ordering of edge weights when choosing which edges to add to the tree, not their absolute values. The minimum spanning tree will still be found correctly regardless of whether the weights are positive or negative.
\end{itemize}

\section{Divide and Conquer \& Convex Hull}
\subsection{Divide and Conquer}
\begin{itemize}
    \item Key steps:
    \begin{itemize}
        \item Divide: Split problem into smaller instances
        \item Conquer: Solve subproblems recursively
        \item Combine: Merge solutions into final answer
    \end{itemize}
    \item Common examples include merge sort, quick sort, binary search, and finding closest pair of points
    \item Master Theorem:
    \begin{itemize}
        \item When we solve a problem by breaking it into smaller pieces, we often get a pattern like:
        \begin{itemize}
            \item To solve a problem of size $n$, we need to solve some number of subproblems (let's call this number $a$)
            \item Each of these subproblems is of size $n/b$ (where $b$ is how much we divide the problem size by)
            \item Plus we need to do some extra work $f(n)$ to combine the results
        \end{itemize}
        \item This pattern is called a recurrence relation
        \item Example: In merge sort:
        \begin{itemize}
            \item We split array in half (so $b = 2$, because we divide size by 2)
            \item We solve two subproblems (so $a = 2$):
            \begin{itemize}
                \item Sort the left half of the array
                \item Sort the right half of the array
            \end{itemize}
            \item We merge the sorted halves (which takes $n$ time, so $f(n) = n$)
            \item So $T(n) = 2T(n/2) + n$
        \end{itemize}
        \item Different example: In binary search:
        \begin{itemize}
            \item We split array in half (so $b = 2$)
            \item We solve only one subproblem (so $a = 1$):
            \begin{itemize}
                \item Search in either the left half OR the right half
                \item We don't need to search both halves because we can determine which half to look in
            \end{itemize}
            \item We do constant work to compare and choose which half (so $f(n) = 1$)
            \item So $T(n) = T(n/2) + 1$
        \end{itemize}
        \item The Master Theorem formula:
        \begin{itemize}
            \item If $T(n) = aT(n/b) + f(n)$ where:
            \begin{itemize}
                \item $a \geq 1$ (we must have at least one subproblem)
                \item $b > 1$ (we must divide the problem into smaller pieces)
                \item $f(n)$ is asymptotically positive ($f(n)$ is positive for most values of $n$, especially the large ones we care about)
            \end{itemize}
            \item Then $T(n)$ is one of these three cases:
            \begin{itemize}
                \item If the extra work $f(n)$ is much smaller than $n^{\log_b(a)}$, then $T(n) = \Theta(n^{\log_b(a)})$
                \item If the extra work $f(n)$ is about the same size as $n^{\log_b(a)}$, then $T(n) = \Theta(n^{\log_b(a)} \log n)$
                \item If the extra work $f(n)$ is much larger than $n^{\log_b(a)}$, then $T(n) = \Theta(f(n))$
            \end{itemize}
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Convex Hull}
A convex hull is the smallest convex polygon that contains all points in a set.
It has several important properties: all points must lie on or inside the hull, no interior angles can be greater than 180 degrees, and it has the minimum possible perimeter that can enclose all points.

\subsubsection{Jarvis March (Gift Wrapping)}
\begin{itemize}
    \item Take the leftmost point as starting point and imagine a horizontal line to the right from it
    \item For each other point, draw a line from the starting point to this other point
    \item Measure the angle between the horizontal line and this new line
    \item Take the other point that creates the largest counterclockwise angle with the horizontal line and consider it part of the hull, the edge to it is the new "current edge"
    \item For each subsequent point on the hull:
    \begin{itemize}
        \item Find the point that makes the largest counterclockwise angle with the current edge
        \item This is done by comparing angles between the current edge and all other points
        \item The point with the largest angle will be the next point on the hull and the edge to it the new "current edge"
    \end{itemize}
    \item Continue until we return to the starting point
    \item Time: $O(nh)$ where $n$ is the total number of points and $h$ is number of points on the hull
    \item Worst case: $O(n^2)$ when all points are on the hull (i.e., when $h = n$)
    \item Optimization: We don't actually need to calculate angles. Instead, we can use cross products to determine which point makes the largest counterclockwise turn. For points A, B, C: if cross product $(B-A) \times (C-A)$ is positive, C is counterclockwise from B and so on.
\end{itemize}
\subsubsection{Graham Scan}
A polar angle is the angle between a point and a reference point relative to a reference direction (usually horizontal right).

\textbf{Steps:}
\begin{itemize}
    \item Find the point with lowest y-coordinate (if tie, take leftmost) - this is our reference point. This point is guaranteed to be on the hull.
    \item Sort all other points by their polar angle in ascending order (counterclockwise) from the reference point (use cross product for speed). This means we'll process points starting from the right of the reference point and moving counterclockwise.
    \item If two points have same polar angle, keep only the furthest one from the reference point (the closer point will be inside the hull)
    \item Start with the first three points in a stack
    \item For each remaining point:
    \begin{itemize}
        \item While the last three points in stack make a right turn (negative cross product) or are collinear (zero cross product), pop the middle point
        \item Push the current point onto stack
    \end{itemize}
    \item The stack now contains the convex hull points in counterclockwise order
\end{itemize}

The time complexity is $O(n \log n)$ due to sorting, and space complexity is $O(n)$ for the stack.
Graham Scan has several advantages over Jarvis March: it's more efficient when many points are on the hull, has a guaranteed $O(n \log n)$ time complexity, and is relatively simple to implement.

\subsubsection{Preparata-Hong (Merge Hull)}
Preparata-Hong is a divide-and-conquer algorithm for finding the convex hull that works in both 2D and 3D.
It's particularly notable for being one of the first efficient algorithms for 3D convex hulls.
The process involves splitting the points into two halves, finding the hulls recursively, and then merging the hulls by finding "bridge" edges. The time complexity is $O(n \log n)$.
Its applications include 3D modeling, computer graphics, and collision detection.
The algorithm is well-suited for parallelization because the recursive subproblems can be solved independently in parallel, and the merging step can also be parallelized.

\textbf{Process for 2D (3D is similar but more complex):}
\begin{itemize}
    \item Split points into two halves (for example by picking a point and dividing the remaining points into those with smaller and larger x-coordinates)
    \item Find hulls recursively:
    \begin{itemize}
        \item Base case: if we have 3 or fewer points, order them clockwise using cross products (like in Graham Scan). This is already a convex hull.
        \item Otherwise, split the points and recursively find the hulls of each half
    \end{itemize}
    \item Merge hulls by finding ``bridge'' edges:
    \begin{itemize}
        \item Find the upper bridge: start with rightmost point of left hull (highest x-coordinate) and leftmost point of right hull (lowest x-coordinate)
        \item Look at next points clockwise on left hull and counterclockwise on right hull
        \item For each hull, if the line between current points would go below its next point, move to that next point
        \item Repeat until we find points where the line between them would go above their next neighbors
        \item Find the lower bridge: start with the same start points as before
        \item Look at next points counterclockwise on left hull and clockwise on right hull
        \item For each hull, if the line between current points would go above its next point, move to that next point
        \item Repeat until we find points where the line between them would go below their next neighbors
        \item Remove all points between the bridges that are not part of the new hull, maintaining clockwise order
    \end{itemize}
\end{itemize}

\subsection{Finding Nearest Points}
\begin{itemize}
    \item Problem: Find the smallest distance between any two points in a 2D plane
    \item Divide-and-conquer approach:
    \begin{itemize}
        \item Sort points by $x$ and $y$ coordinates ($O(n \log n)$)
        \item Split points into left and right halves
        \item Find closest pairs in each half recursively
        \item Check for closer pairs that cross the dividing line
    \end{itemize}
    \item Time complexity: $O(n \log n)$
    \begin{itemize}
        \item $a = 2$ (we split into two subproblems)
        \item $b = 2$ (each subproblem is half the size)
        \item $f(n) = n$ (we need to check points in the strip)
        \item Using Master Theorem: $n^{\log_2(2)} = n$, and $f(n) = n$, so we're in case 2
        \item Therefore $T(n) = \Theta(n \log n)$
    \end{itemize}
    \item Key insight: In the strip around the dividing line, each point only needs to be compared with at most 7 other points
    \item Base case: When we have 3 or fewer points, use brute force
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain what is meant by a divide-and-conquer algorithm.
    \item \textbf{A:} Divide the problem into smaller subproblems, solve them recursively, and combine their solutions to solve the original problem.

    \item \textbf{Q:} Explain what the Master theorem is about.
    \item \textbf{A:} The Master theorem provides a way to solve recurrence relations of the form $T(n) = aT(n/b) + f(n)$ by comparing the growth of $f(n)$ with $n^{\log_b(a)}$.

    \item \textbf{Q:} What is a convex hull?
    \item \textbf{A:} The smallest convex polygon containing all points, with no interior angles greater than 180 degrees.

    \item \textbf{Q:} Explain the Graham scan algorithm.
    \item \textbf{A:} Graham scan sorts points by polar angle, then uses a stack to build the hull by removing points that create concave angles.

    \item \textbf{Q:} Explain the main ideas of the Preparata-Hong algorithm.
    \item \textbf{A:} Preparata-Hong is a divide-and-conquer algorithm for 3D convex hull that splits points, finds hulls recursively, and merges them efficiently.

    \item \textbf{Q:} Why is it important to compare either $\alpha$ or $\beta$ with $\gamma$ first in different situations? What is likely to happen otherwise?
    \item \textbf{A:} When doing geometric computations, especially with floating-point numbers, the order of comparisons can affect numerical stability. For example, when comparing three angles $\alpha$, $\beta$, and $\gamma$, we should always compare them in a consistent order (like always comparing $\alpha$ with $\gamma$ first, then $\beta$ with $\gamma$). This helps avoid floating-point errors that can occur due to different orders of operations. If we don't maintain a consistent order, we might get different results for the same geometric situation due to rounding errors in floating-point arithmetic.

    \item \textbf{Q:} How can you know if a point p is between q and r on a line?
    \item \textbf{A:} Use cross product to check collinearity and dot product to check if p is between q and r on the line.

    \item \textbf{Q:} How can you know the direction (left, right, or straight) when going from a point pr through ps to pt?
    \item \textbf{A:} Use the cross product of vectors ps-pr and pt-ps; positive means left turn, negative means right turn, zero means straight.

    \item \textbf{Q:} What's the difference between Jarvis March and Graham Scan in terms of when each is more efficient?
    \item \textbf{A:} Jarvis March is more efficient when the number of points on the hull (h) is small, as it runs in O(nh) time. Graham Scan is better when most points are on the hull, as it runs in O(n log n) time regardless of hull size. Graham Scan is generally preferred for large datasets as its worst case is better.

    \item \textbf{Q:} How does the time complexity of finding the closest pair of points using divide and conquer compare to a brute force approach?
    \item \textbf{A:} The divide and conquer approach runs in O(n log n) time, while brute force would be O(n²). The improvement comes from only needing to check a limited number of points in the strip between divided regions.

    \item \textbf{Q:} Why do we need to check points in the 'strip' when finding the closest pair of points? What's the maximum number of points we need to check in the strip?
    \item \textbf{A:} We need to check the strip because the closest pair might be split across the dividing line. The maximum number of points we need to check in the strip is 7, as any more points would violate the minimum distance property we've already established.

    \item \textbf{Q:} In the Master Theorem, what happens when $f(n)$ grows faster than $n^{\log_b(a)}$? Give an example.
    \item \textbf{A:} When $f(n)$ grows faster than $n^{\log_b(a)}$, the time complexity is dominated by $f(n)$, giving us $T(n) = \Theta(f(n))$. For example, if $T(n) = 2T(n/2) + n^2$, then $n^{\log_2(2)} = n$, and since $n^2$ grows faster than $n$, we get $T(n) = \Theta(n^2)$.

    \item \textbf{Q:} How does the choice of starting point affect Jarvis March? Does it matter which point we start with?
    \item \textbf{A:} The choice of starting point doesn't affect the correctness of Jarvis March, but it can affect the number of points we need to check. Starting with the leftmost point is common because it's guaranteed to be on the hull, but any point on the hull would work.

    \item \textbf{Q:} How can we handle collinear points in convex hull algorithms? What special cases do we need to consider?
    \item \textbf{A:} For collinear points, we typically want to keep only the outermost points on the hull. This means when three points are collinear, we should keep the two endpoints and remove the middle point. We need to handle this in both Jarvis March and Graham Scan to avoid including unnecessary points.

    \item \textbf{Q:} Why is it important that the Master Theorem's f(n) is asymptotically positive? What could go wrong if it wasn't?
    \item \textbf{A:} The Master Theorem requires f(n) to be asymptotically positive because negative work doesn't make sense in the context of algorithm complexity. If f(n) could be negative, it would mean the algorithm is doing "negative work" in some steps, which doesn't correspond to any real computation. This would make the recurrence relation meaningless for analyzing algorithm complexity.
\end{itemize}

\section{Dynamic Programming}
\subsection{Main Ideas}
Dynamic Programming is a way to solve problems by breaking them into smaller subproblems and storing solutions to avoid solving them again.
Key characteristics:
\begin{itemize}
    \item Like divide-and-conquer, but subproblems overlap
    \item Store solutions to subproblems to avoid solving them again
    \item Use when:
    \begin{itemize}
        \item Problem has overlapping subproblems
        \item Subproblems can be combined to solve main problem
        \item We can write a recurrence relation
    \end{itemize}
\end{itemize}

\subsection{Recurrence Relations}
A recurrence relation is like a recipe that tells you how to solve a problem using solutions to smaller versions of the same problem.
It has two parts:
\begin{itemize}
    \item The formula that shows how to combine smaller solutions
    \item The base cases (smallest problems that we can solve directly)
\end{itemize}

\subsubsection{Examples}
\textbf{Fibonacci}
\begin{itemize}
    \item Formula: $fib(n) = fib(n-1) + fib(n-2)$
    \item Base cases: $fib(0) = 0$, $fib(1) = 1$
\end{itemize}

\textbf{Longest Increasing Subsequence}
\begin{itemize}
    \item Formula: $lis(i) = 1 + \max(lis(j))$ where \\~ $j < i$ and $array[j] < array[i]$
    \item Base case: $lis(0) = 1$
\end{itemize}

\textbf{Edit Distance}
\begin{itemize}
    \item Formula: $ed(i,j) = \min(\text{delete}, \text{insert}, \text{replace})$
    \item Where:
    \begin{itemize}
        \item delete = $ed(i-1,j) + 1$
        \item insert = $ed(i,j-1) + 1$
        \item replace = $ed(i-1,j-1) + cost$
    \end{itemize}
    \item Base case: $ed(0,0) = 0$
\end{itemize}

\subsection{Two Approaches}
\subsubsection{Top-down (memoization):}
\begin{itemize}
    \item Start with main problem
    \item Solve subproblems as needed
    \item Store results in a table
\end{itemize}

\subsubsection{Bottom-up (tabulation):}
\begin{itemize}
    \item Start with smallest subproblems
    \item Build up to main problem
    \item Fill table systematically
\end{itemize}

\subsection{Steps to solve a DP problem:}
\begin{enumerate}
    \item Identify the subproblems
    \item Write the recurrence relation
    \item Decide on approach (top-down or bottom-up)
    \item Implement the solution
    \item Analyze time and space complexity
\end{enumerate}

\subsection{Sequence Alignment}
Sequence alignment is finding the best way to align two strings by inserting gaps.
\begin{itemize}
    \item Used to compare DNA sequences, protein sequences, or text
    \item Goal: Maximize similarity or minimize cost of alignment
\end{itemize}
\subsubsection{Process:}
\begin{itemize}
    \item Use 2D table where cell (i,j) represents best alignment of first i characters of string 1 and first j characters of string 2
    \item For each cell, consider three options:
    \begin{itemize}
        \item Match/mismatch: align current characters
        \item Gap in first string: skip character in string 1
        \item Gap in second string: skip character in string 2
    \end{itemize}
\end{itemize}
\subsubsection{Time complexity:}
$O(N \times M)$ where $N$ and $M$ are string lengths
\subsubsection{Applications:}
\begin{itemize}
    \item Bioinformatics: comparing DNA or protein sequences
    \item Text processing: finding similar words or documents
    \item Version control: finding differences between files
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain what is meant by dynamic programming.
    \item \textbf{A:} Solving a problem by breaking it into overlapping subproblems and storing their solutions to avoid redundant calculations.

    \item \textbf{Q:} What is sequence alignment and how can it be done?
    \item \textbf{A:} Sequence alignment finds the best way to align two strings by inserting gaps; it's done using dynamic programming to maximize similarity or minimize cost.

    \item \textbf{Q:} What are the key characteristics of a problem that makes it suitable for dynamic programming?
    \item \textbf{A:} A problem is suitable for DP if it has overlapping subproblems (same subproblems are solved multiple times) and optimal substructure (optimal solution can be constructed from optimal solutions of subproblems).

    \item \textbf{Q:} Compare and contrast top-down (memoization) and bottom-up (tabulation) approaches in dynamic programming.
    \item \textbf{A:} Top-down starts with the main problem and solves subproblems as needed, storing results in a table. Bottom-up starts with smallest subproblems and builds up to the main problem, filling the table systematically. Top-down can be more intuitive and only computes needed subproblems, while bottom-up avoids recursion overhead and can be more space-efficient.

    \item \textbf{Q:} In the Edit Distance problem, explain why we need to consider all three operations (delete, insert, replace) and how they contribute to the final solution.
    \item \textbf{A:} We need all three operations because they represent different ways to transform one string into another. Delete removes a character from the first string, insert adds a character to the first string, and replace changes a character in the first string. The algorithm chooses the minimum cost among these operations at each step to find the optimal transformation sequence.

    \item \textbf{Q:} How does the time and space complexity of a dynamic programming solution typically compare to a naive recursive solution?
    \item \textbf{A:} A naive recursive solution often has exponential time complexity due to solving the same subproblems multiple times. Dynamic programming reduces this to polynomial time by storing solutions to subproblems. Space complexity is typically O(n) or O(n²) for DP, while naive recursion can use O(n) space for the call stack plus additional space for redundant computations.

    \item \textbf{Q:} Explain how you would modify the Edit Distance algorithm to also return the sequence of operations that leads to the minimum distance.
    \item \textbf{A:} We can add a second table to store the operation (delete, insert, or replace) that led to each cell's value. When filling the table, we record which operation gave the minimum value. After computing the minimum distance, we can trace back through the table following these recorded operations to reconstruct the sequence.

    \item \textbf{Q:} What is the difference between overlapping subproblems and independent subproblems? Why is this distinction important for dynamic programming?
    \item \textbf{A:} Overlapping subproblems occur when the same subproblem is solved multiple times in a recursive solution. Independent subproblems are solved only once. This distinction is crucial because dynamic programming is only beneficial for problems with overlapping subproblems - there's no need to store solutions if each subproblem is solved exactly once.
\end{itemize}

\section{Network Flow}
\subsection{Main Ideas}
Network flow is about finding the maximum amount of flow that can be sent from a source node to a sink node in a directed graph where each edge has a capacity.

\subsubsection{Applications}
\begin{itemize}
    \item Finding maximum matching in bipartite graphs
    \item Finding maximum number of edge-disjoint paths
    \item Modeling traffic flow in networks
    \item Finding minimum cut in a graph
    \item Modeling water pipes and electrical systems
    \item Ecological applications (nutrient flow)
\end{itemize}

\subsection{Ford-Fulkerson Algorithm}
\subsubsection{Main Idea}
Keep finding paths with available capacity and add flow until no more paths exist.

\subsubsection{Steps}
\begin{enumerate}
    \item Start with zero flow
    \item Find a path from source to sink with available capacity
    \item Add flow along this path
    \item Update residual capacities
    \item Repeat until no more paths exist
\end{enumerate}

\subsubsection{Residual Graph}
\begin{itemize}
    \item Forward edges: remaining capacity
    \item Backward edges: current flow (can be "undone")
\end{itemize}

\subsubsection{Time Complexity}
$O(E \times \text{max\_flow})$ where:
\begin{itemize}
    \item $E$ is number of edges
    \item max\_flow is the maximum possible flow
    \item Each path finding takes $O(E)$ time
    \item We might need to find max\_flow paths
\end{itemize}

\subsubsection{Correctness}
The Ford-Fulkerson algorithm is correct because:
\begin{itemize}
    \item It always terminates (flow can only increase, and there's a maximum possible flow)
    \item When it terminates, no augmenting path exists
    \item By the max-flow min-cut theorem, this means we've found the maximum flow
    \item The residual graph allows us to "undo" flow if we find a better path
\end{itemize}

\subsection{Bipartite Graph Matching}
A bipartite graph is a graph where we can split all the vertices into two separate groups (let's call them group $L$ and group $R$), and every edge in the graph must connect a vertex from one group to a vertex in the other group. In other words, you can't have edges between vertices in the same group. This structure makes bipartite graphs perfect for modeling matching problems where we need to pair things from one group with things from another group, like matching students to courses or workers to jobs.

\subsubsection{Problem Definition}
Given a bipartite graph $G = (L \cup R, E)$, where $L$ and $R$ are our two groups of vertices and $E$ is the set of all edges connecting vertices between these groups, find the maximum number of edges that can be matched such that no two edges share a vertex.

\subsubsection{Reduction to Max Flow}
\begin{enumerate}
    \item Add source node connected to all vertices in $L$
    \item Add sink node connected from all vertices in $R$
    \item Set all edge capacities to 1
    \item Find maximum flow
    \item The edges with flow 1 form the maximum matching
\end{enumerate}

\subsubsection{Time Complexity}
$O(VE)$ where:
\begin{itemize}
    \item $V$ is number of vertices
    \item $E$ is number of edges
    \item Each augmenting path increases flow by 1
    \item Maximum flow is at most $V/2$
\end{itemize}

\subsubsection{Applications}
\begin{itemize}
    \item Job assignment problems
    \item Dating/matching applications
    \item Resource allocation
    \item Task scheduling
\end{itemize}

\subsection{Goldberg-Tarjan (Push-Relabel)}
\subsubsection{Key Components}
\begin{itemize}
    \item Height labels for nodes
    \item Excess flow at each node
    \item Push flow to lower neighbors
    \item Relabel nodes when stuck
\end{itemize}

\subsubsection{Time Complexity}
$O(V^2 \times E)$ where:
\begin{itemize}
    \item $V$ is number of vertices
    \item $E$ is number of edges
    \item Better than Ford-Fulkerson for large capacities
\end{itemize}

\subsubsection{Advantages}
\begin{itemize}
    \item Pushes full available flow in each step
    \item Not affected by large edge capacities
    \item Often faster in practice
\end{itemize}

\subsection{Handling Large Capacities}
\subsubsection{Why Ford-Fulkerson Can Be Slow}
\begin{itemize}
    \item Basic version increments flow by 1 unit at a time
    \item With large capacities (e.g., 1,000,000), needs many iterations
    \item Example: If max flow is 1,000,000, might need 1,000,000 iterations
\end{itemize}

\subsubsection{Solutions}
\begin{itemize}
    \item Capacity scaling:
    \begin{itemize}
        \item Begin with largest power of 2 less than max capacity
        \item Halve the step size each iteration
        \item Reduces iterations from $O(\text{max\_flow})$ to $O(\log \text{max\_flow})$
    \end{itemize}
    \item Use Push-Relabel algorithm instead
    \item Use binary search over possible flow values
\end{itemize}

\subsubsection{When to Use Which Algorithm}
\begin{itemize}
    \item Ford-Fulkerson with capacity scaling:
    \begin{itemize}
        \item Good for sparse graphs
        \item Easy to implement
        \item Works well with small to medium capacities
    \end{itemize}
    \item Push-Relabel:
    \begin{itemize}
        \item Better for dense graphs
        \item Better for very large capacities
        \item More complex to implement
        \item Often faster in practice
    \end{itemize}
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} What is network flow about? Give an example of when it can be used.
    \item \textbf{A:} Network flow finds the maximum flow from source to sink in a directed graph with edge capacities. It's used for maximum matching, minimum cut, and traffic optimization.

    \item \textbf{Q:} Explain the Ford-Fulkerson algorithm and why it is correct. What is its time complexity, and why?
    \item \textbf{A:} Ford-Fulkerson repeatedly finds augmenting paths and adds flow until no more paths exist. It's correct because it always finds the maximum flow. The time complexity is $O(E \times \text{max\_flow})$ because each path finding takes $O(E)$ time and we might need to find $\text{max\_flow}$ paths.

    \item \textbf{Q:} Explain the Goldberg-Tarjan (preflow-push) algorithm and why it is correct.
    \item \textbf{A:} Goldberg-Tarjan uses node heights and excess flow, pushing flow to lower neighbors and relabeling when stuck. It's correct because it maintains the height property and terminates with maximum flow.

    \item \textbf{Q:} What is a bipartite graph, and how can you determine if a graph is bipartite?
    \item \textbf{A:} A bipartite graph can be divided into two sets with no edges within the same set. You can determine if a graph is bipartite using BFS or DFS with two colors, coloring each vertex opposite to its neighbors. If you can't do this coloring without conflicts, the graph isn't bipartite.

    \item \textbf{Q:} What is the relationship between maximum flow and minimum cut in a network?
    \item \textbf{A:} The maximum flow equals the capacity of the minimum cut (max-flow min-cut theorem). This means the bottleneck in the network is determined by the minimum cut.

    \item \textbf{Q:} Why do we need backward edges in the residual graph for Ford-Fulkerson?
    \item \textbf{A:} Backward edges allow us to "undo" flow if we find a better path. They represent the current flow that can be redirected, which is crucial for finding the optimal solution.

    \item \textbf{Q:} In bipartite matching, why do we set all edge capacities to 1 when reducing to max flow?
    \item \textbf{A:} Setting capacities to 1 ensures that each vertex can only be matched once, as the flow through any edge can be at most 1. This directly corresponds to the matching constraint where no two edges can share a vertex.

    \item \textbf{Q:} What is the difference between a maximum matching and a perfect matching in a bipartite graph?
    \item \textbf{A:} A maximum matching is the largest possible set of edges where no two edges share a vertex. A perfect matching is a maximum matching where every vertex is matched (only possible if both groups have the same size).
\end{itemize}

\section{Hollow Heap}
\subsection{Understanding Amortized Time}
Amortized time complexity is a way to analyze the average time per operation over a sequence of operations. While some individual operations might be expensive, the total cost is spread out (amortized) across all operations.

\subsection{Overview}
A type of heap data structure that supports:
\begin{itemize}
    \item Insert: O(1) amortized time
    \item Delete-min: O(log n) amortized time
    \item Decrease-key: O(1) amortized time
\end{itemize}

\subsection{Key Features}
\begin{itemize}
    \item Multiple root nodes allowed
    \item Nodes can be "hollow" (deleted) or "full" (active)
    \item Links between nodes can be "solid" or "dashed"
\end{itemize}

\subsection{Operations}
\begin{itemize}
    \item \textbf{Insert:} Create new node and link to existing roots
    \item \textbf{Delete-min:} Remove minimum root, merge its children
    \item \textbf{Decrease-key:} Cut subtree and make it a new root
\end{itemize}

\subsection{Advantages}
\begin{itemize}
    \item Better theoretical bounds than Fibonacci heaps
    \item Simpler implementation
    \item Good for algorithms needing many decrease-key operations
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain how hollow heaps work. Focus on the simplest version with multiple root nodes.
    \item \textbf{A:} In the simplest version, hollow heaps maintain multiple root nodes where each root represents a potential minimum. Nodes can be either full (active) or hollow (deleted). When inserting, we create a new root. For decrease-key, we cut the subtree and make it a new root. Delete-min removes the minimum root and merges its children. The structure uses both solid and dashed links to maintain efficiency, with solid links forming the main structure and dashed links helping with decrease-key operations.
\end{itemize}

\section{NP-Completeness}
\subsection{Polynomial Time}
Polynomial time means the time needed to solve the problem grows as a polynomial function of the input size.
For example, if the input size is $n$, the time might grow as $n^2$ or $n^3$, but not as $2^n$ (exponential) or $n!$ (factorial).
Problems that can be solved in polynomial time are considered "efficient" or "tractable", meaning they're solvable in a reasonable amount of time even for large inputs.

\subsection{NP}
NP stands for "Nondeterministic Polynomial time".
It's a class of problems where, given a potential solution, we can verify if it's correct in polynomial time.
The key characteristic is that while we can quickly check if a solution is correct, we don't know of any efficient way to find the solution itself.
\subsection{Complexity Classes}
\subsubsection{What are Complexity Classes?}
Complexity classes are groups of problems that are similar in how hard they are to solve. "Hard" means how much time or memory they need. Problems in the same class can be solved in similar ways.

\subsubsection{Main Classes}
\begin{itemize}
    \item P: Problems that can be solved in polynomial time
    \begin{itemize}
        \item Example: Sorting, shortest path
        \item These are the "easy" problems
    \end{itemize}
    \item NP: "Nondeterministic Polynomial time"
    \begin{itemize}
        \item Problems where solutions can be verified in polynomial time
        \item If we could "guess" the right answer, we could verify it quickly
        \item Example: Given a path, can verify if it's a Hamiltonian cycle
    \end{itemize}
    \item NP-complete: Hardest problems in NP
    \begin{itemize}
        \item If we could solve any NP-complete problem quickly, we could solve all NP problems quickly
        \item No known polynomial-time solution exists
    \end{itemize}
\end{itemize}

\subsection{Common NP-complete Problems}
\subsubsection{Vertex Cover}
\begin{itemize}
    \item Find smallest set of vertices that covers all edges
    \item Each edge must touch at least one vertex in the set
    \item Example: In a network, find minimum servers to monitor all connections
\end{itemize}

\subsubsection{Independent Set}
\begin{itemize}
    \item Find largest set of vertices with no edges between them
    \item No two vertices in the set can be connected
    \item Example: Find maximum number of non-conflicting tasks
\end{itemize}

\subsubsection{Set Cover}
\begin{itemize}
    \item Given a collection of sets, find smallest number of sets that cover all elements
    \item Each element must be in at least one chosen set
    \item Example: Choose minimum number of radio stations to cover all cities
\end{itemize}

\subsubsection{Traveling Salesman Problem (TSP)}
\begin{itemize}
    \item Find shortest route visiting all cities
    \item Must visit each city exactly once
    \item Example: Optimize delivery route for a truck
\end{itemize}

\subsubsection{Graph Coloring}
\begin{itemize}
    \item Color vertices so no adjacent vertices have same color
    \item Find minimum number of colors needed
    \item Example: Schedule exams so no student has two exams at same time
\end{itemize}

\subsection{SAT Solvers}
\begin{itemize}
    \item Algorithms to solve boolean satisfiability problems
    \item Unit Propagation:
    \begin{itemize}
        \item If a clause has only one literal, that literal must be true
        \item Example: If (A $\lor$ B $\lor$ C) and A=false, B=false, then C must be true
        \item Used to simplify formula and find forced assignments
    \end{itemize}
\end{itemize}

\subsection{Proving NP-completeness}
\subsubsection{Two Steps}
\begin{enumerate}
    \item Show it's in NP:
    \begin{itemize}
        \item Given a solution, can verify it's correct in polynomial time
        \item Example: For vertex cover, can check if chosen vertices cover all edges
    \end{itemize}
    \item Show it's NP-hard:
    \begin{itemize}
        \item Take a known NP-complete problem
        \item Show how to convert any instance of that problem into an instance of your problem
        \item The conversion must take polynomial time
    \end{itemize}
\end{enumerate}

\subsubsection{Why it Matters}
\begin{itemize}
    \item If a problem is NP-complete, we probably can't find an efficient solution
    \item Instead, we need to use:
    \begin{itemize}
        \item Approximation algorithms
        \item Heuristics
        \item Special cases
        \item Exponential-time algorithms for small inputs
    \end{itemize}
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} What does it mean that a problem is NP-complete?
    \item \textbf{A:} A problem is NP-complete if it's in NP (solutions can be verified in polynomial time) and every NP problem can be reduced to it in polynomial time.

    \item \textbf{Q:} If you want to prove that a new problem is NP-complete, how would you do?
    \item \textbf{A:} Show it's in NP (verify solutions in polynomial time) and reduce a known NP-complete problem to it in polynomial time.

    \item \textbf{Q:} Explain how the first NP-complete problem was shown to be NP-complete.
    \item \textbf{A:} Boolean Satisfiability (SAT) was proven NP-complete by Cook-Levin theorem, showing any NP problem can be reduced to SAT in polynomial time.

    \item \textbf{Q:} Explain how it can be shown that Hamiltonian cycle is NP-complete.
    \item \textbf{A:} Reduce from 3-SAT by creating gadgets for variables and clauses, showing a Hamiltonian cycle exists if and only if the formula is satisfiable.

    \item \textbf{Q:} Explain how it can be shown that the Traveling salesman problem is NP-complete.
    \item \textbf{A:} Reduce from Hamiltonian cycle by setting edge weights to 1 for existing edges and 2 for non-existent edges, then solve TSP with bound n.

    \item \textbf{Q:} Explain how it can be shown that graph coloring is NP-complete.
    \item \textbf{A:} Reduce from 3-SAT by creating a graph where each variable and its negation are connected, and each clause forms a triangle, showing 3-coloring exists if and only if the formula is satisfiable.

    \item \textbf{Q:} What is the difference between NP and NP-complete problems?
    \item \textbf{A:} NP problems can have their solutions verified in polynomial time. NP-complete problems are the hardest problems in NP - if we could solve any NP-complete problem efficiently, we could solve all NP problems efficiently.

    \item \textbf{Q:} Why is it important to know if a problem is NP-complete?
    \item \textbf{A:} It tells us that we probably can't find an efficient (polynomial-time) solution. Instead, we need to use approximation algorithms, heuristics, or accept that the problem will be slow to solve for large inputs.

    \item \textbf{Q:} What is a reduction in the context of NP-completeness?
    \item \textbf{A:} A reduction is a way to convert one problem into another. If we can reduce problem A to problem B in polynomial time, and we know A is hard, then B must be at least as hard as A.

    \item \textbf{Q:} Why do we use 3-SAT as a starting point for many NP-completeness proofs?
    \item \textbf{A:} 3-SAT is a well-understood NP-complete problem that's relatively simple to work with. It's often easier to reduce from 3-SAT to other problems than to reduce from more complex problems.

    \item \textbf{Q:} What is the relationship between P and NP?
    \item \textbf{A:} P is the set of problems we can solve in polynomial time. NP is the set of problems where we can verify solutions in polynomial time. We know P is a subset of NP, but we don't know if P equals NP - this is the famous P vs NP question.

    \item \textbf{Q:} How can we solve NP-complete problems in practice?
    \item \textbf{A:} We can use approximation algorithms to get good (but not optimal) solutions, heuristics to find solutions quickly, or exact algorithms for small instances. The choice depends on whether we need optimal solutions and how large our inputs are.

    \item \textbf{Q:} Why can't we solve Set Cover by just picking sets that cover the most uncovered elements?
    \item \textbf{A:} This greedy approach doesn't always find the optimal solution. Sometimes picking a set that covers fewer elements now leads to a better overall solution later. For example, with elements \{1,2,3,4,5\} and sets A=\{1,2,3\}, B=\{2,3,4\}, C=\{3,4,5\}, D=\{1,4,5\}, the greedy approach might pick 3 sets while the optimal solution uses just 2 sets.

    \item \textbf{Q:} Explain what unit propagation in SAT-solvers mean.
    \item \textbf{A:} Unit propagation is a simplification technique in SAT solvers where if a clause has only one remaining unassigned literal (all others are false), that literal must be true to satisfy the clause.
    For example, in the clause (A $\lor$ B $\lor$ C), if A=false and B=false, then C must be true. This allows the solver to make forced assignments and simplify the formula, often leading to a cascade of other forced assignments.
\end{itemize}

\section{Linear Programming}
Linear Programming (LP) is a method to find the best outcome in a mathematical model where all relationships are linear (straight lines). The goal is to maximize or minimize a linear objective function while satisfying a set of linear constraints.

\subsection{Key Components}
\begin{itemize}
    \item Variables: What we're trying to find ($x_1, x_2, ...$)
    \item Objective Function: What we want to maximize/minimize
    \item Constraints: Limits on the variables
    \item Feasible Region: All points that satisfy the constraints
\end{itemize}

\subsection{Example Problem}
Here's a simple example of a linear programming problem:
\begin{itemize}
    \item Goal: Maximize $3x + 2y$ (this is our objective function)
    \item Constraints (these are the conditions our solution must satisfy):
    \begin{itemize}
        \item $x + y \leq 10$ (total of x and y cannot exceed 10)
        \item $2x + y \leq 15$ (twice x plus y cannot exceed 15)
        \item $x \geq 0$ (x must be non-negative)
        \item $y \geq 0$ (y must be non-negative)
    \end{itemize}
\end{itemize}

\subsection{Solving Methods}
\subsubsection{Simplex Algorithm}
\begin{itemize}
    \item Moves along edges of feasible region
    \item Stops at optimal vertex
    \item Time complexity: Usually polynomial, but can be exponential
\end{itemize}

\subsubsection{Interior Point Methods}
\begin{itemize}
    \item Moves through interior of feasible region
    \item Often faster for large problems
    \item Polynomial time complexity
\end{itemize}

\subsection{Integer Linear Programming (ILP)}
Integer Linear Programming is similar to regular LP, but with the additional constraint that variables must be integers. This makes the problem much harder to solve.

\subsubsection{Applications}
\begin{itemize}
    \item Scheduling problems
    \item Resource allocation
    \item Network design
\end{itemize}

\subsubsection{Solving Methods}
\begin{itemize}
    \item Branch and Bound
    \item Cutting Plane
    \item Often use LP relaxation as starting point
\end{itemize}

\subsubsection{2D Bin Packing}
A practical example of optimization in manufacturing and material cutting:
\begin{itemize}
    \item Problem: Fit multiple shapes onto a fixed-size sheet of material
    \item Variables: 
    \begin{itemize}
        \item Continuous: Position (x,y) and rotation of each shape
        \item Binary: Whether each shape is used or not
    \end{itemize}
    \item Constraints:
    \begin{itemize}
        \item Shapes must fit within sheet boundaries
        \item Shapes cannot overlap
        \item Each shape must be placed (or not at all)
    \end{itemize}
    \item Objective: Maximize number of shapes or minimize waste
    \item Challenges:
    \begin{itemize}
        \item Non-linear constraints (for non-overlapping)
        \item Trigonometric functions (for rotations)
        \item NP-hard complexity
    \end{itemize}
    \item Classification: Mixed Integer Non-Linear Programming (MINLP)
    \item Practical solutions:
    \begin{itemize}
        \item Heuristic approaches
        \item Approximation algorithms
        \item Specialized software
    \end{itemize}
\end{itemize}

\subsection{Applications}
\begin{itemize}
    \item Resource allocation
    \item Production planning
    \item Transportation problems
    \item Network flow optimization
    \item Portfolio optimization
    \item Diet problems
    \item Game theory
\end{itemize}

\subsection{Duality}
\begin{itemize}
    \item Every LP has a dual problem
    \item Dual of maximization is minimization
    \item Dual of constraints are variables
    \item Strong duality: Optimal values are equal
    \item Weak duality: Dual gives bound on primal
\end{itemize}

\subsection{Sensitivity Analysis}
\begin{itemize}
    \item How changes in parameters affect solution
    \item Shadow prices: Value of relaxing constraints
    \item Range of validity for current solution
    \item Important for real-world applications
\end{itemize}

\subsection{Example Questions}
\begin{itemize}
    \item \textbf{Q:} Explain what the simplex algorithm can do (but not why it works).
    \item \textbf{A:} The simplex algorithm finds the optimal solution to a linear programming problem by moving along edges of the feasible region to vertices with better objective values.

    \item \textbf{Q:} Explain what the branch-and-bound paradigm is and how it can be used in integer linear programming.
    \item \textbf{A:} Branch-and-bound solves integer programs by solving relaxed linear programs, branching on fractional variables, and using bounds to prune the search tree.
\end{itemize}

\end{multicols}
\end{document} 